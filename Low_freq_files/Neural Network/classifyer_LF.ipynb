{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for making classification on LF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from data_handling_L1 import get_data, sliding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "PATH_TO_L1 = '//NAS24/solo/remote/data/L1'\n",
    "PATH_TO_MODEL = 'C:/Githubs/kandidat/Low_freq_files/Neural Network/model_low_freq.pt'\n",
    "#Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(E, V, EPOCH, start_ind, window_size=512):\n",
    "    '''Preprocesses data for model.\n",
    "    1. Slices data from start_ind and window_size\n",
    "    2. Shapes into correct format\n",
    "    3. Removes bias\n",
    "    4. Normalizes each input channel with respect to max\n",
    "    Returns pytorch tensor'''\n",
    "    ind = start_ind\n",
    "    #Slice the data for prediction\n",
    "    time_processed = (np.array(EPOCH[ind:ind+window_size]) - EPOCH[ind]) / 10**9 #convert ns to s\n",
    "    E1_window = np.array(E[ind:ind+window_size, 0])\n",
    "    E2_window = np.array(E[ind:ind+window_size, 1])\n",
    "    V_window = np.array(V[ind:ind+window_size])\n",
    "    \n",
    "    #Reshape the data\n",
    "    data_shaped = np.array([V_window, E1_window, E2_window]).reshape(3, 512)\n",
    "    \n",
    "    #Remove bias\n",
    "    median = np.median(data_shaped, axis=1, keepdims=True)\n",
    "    data_nobias = data_shaped - median\n",
    "    \n",
    "    #Normalize data for each channel (3)\n",
    "    max_vals = np.max(np.abs(data_nobias), axis=1, keepdims=True)\n",
    "    data_normalized = data_nobias / max_vals\n",
    "    \n",
    "    return time_processed, data_normalized#, problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the architecture for the neural net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(8,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create neural network\n",
    "model = ConvNet()\n",
    "\n",
    "#Load trained variables\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "#Set evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_13192\\4219561328.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "6142\n",
      "2022-01-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "overlap = 0.2\n",
    "batch_size = 100\n",
    "\n",
    "save_as = 'no.pkl'\n",
    "plot = 'day'\n",
    "#%matplotlib inline\n",
    "%matplotlib qt\n",
    "\n",
    "start_date_str = '20220127' #20220302\n",
    "end_date_str = '20220128' #20220321\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "\n",
    "data_dic = {}\n",
    "for root, dirs, files in os.walk(PATH_TO_L1):    #iterate over L1 data\n",
    "    for file in files:\n",
    "        if 'rpw-lfr-surv-cwf-cdag' in file:\n",
    "                date_str = file.split('_')[3]\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                if start_date <= date < end_date:\n",
    "                    CURRENT_PATH = f'{PATH_TO_L1}/{file[-16:-12]}/{file[-12:-10]}/{file[-10:-8]}/{file}'\n",
    "                    #Load file\n",
    "                    E, V, EPOCH  = get_data(CURRENT_PATH)\n",
    "                    Ys = [V, E[:,0], E[:,1]]\n",
    "                    #Slice day into windows\n",
    "                    start_indices = sliding_data(E, overlap, window_size)\n",
    "                    good_ind = []\n",
    "                    ind_dust = []\n",
    "                    predictions = np.array([])\n",
    "                    good_pred = []\n",
    "                    for i in range(0, len(start_indices), batch_size):\n",
    "                        batch_indices = start_indices[i:i+batch_size]\n",
    "                        batch_time = []\n",
    "                        batch_data = []\n",
    "                        for ind in batch_indices:\n",
    "                            #Preprocess data for prediction\n",
    "                            time, data = pre_process(E, V, EPOCH, ind)\n",
    "                            for i in range(len(time) - 1):\n",
    "                                #Lowest time between data points should be 1/16 s\n",
    "                                if time[i+1] - time[i] > 0.063:\n",
    "                                    print('Gap in data detected')\n",
    "                                    break\n",
    "                            else:\n",
    "                                batch_time.append(time)\n",
    "                                batch_data.append(data)\n",
    "                                good_ind.append(ind)\n",
    "                                \n",
    "                        model_data = torch.from_numpy(np.stack(batch_data, 0)).to(device)       \n",
    "                        batch_pred = model(model_data).cpu().detach().numpy()[:,1]\n",
    "                        predictions = np.append(predictions, batch_pred)\n",
    "\n",
    "                    print(len(good_ind))\n",
    "                    prev_pos = False\n",
    "                    if plot == 'window':\n",
    "                        titles = ['V', 'E1', 'E2', 'Quality Flag']\n",
    "                        #Qflag = cdflib.cdfread.CDF(CURRENT_PATH)['BIAS_ON_OFF']\n",
    "                        Ys = [V, E[:,0], E[:,1]]    \n",
    "                    for i in range(len(predictions)):\n",
    "                        if predictions[i] > 0.5 and not prev_pos:\n",
    "                            prev_pos = True\n",
    "                            ind_dust.append(good_ind[i])\n",
    "                            if plot == 'window':\n",
    "                                fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                                for i_plt in range(3):\n",
    "                                    axs[i_plt].plot(EPOCH[ind_dust[-1]:ind_dust[-1]+window_size], \\\n",
    "                                        Ys[i_plt][ind_dust[-1]:ind_dust[-1]+window_size])\n",
    "                                    axs[i_plt].set_title(titles[i_plt])\n",
    "                                #axs[3].plot(EPOCH[ind_dust[-1]:ind_dust[-1]+window_size], Qflag[ind_dust[-1]:ind_dust[-1]+window_size])\n",
    "                                fig.suptitle(f'Prediction = {predictions[i]:.2f}')\n",
    "                                fig.supxlabel('Time [ns]')\n",
    "                                plt.show()\n",
    "                        else:\n",
    "                            prev_pos = False                        \n",
    "\n",
    "                    print(date)\n",
    "                    data_dic[date_str] = EPOCH[ind_dust]\n",
    "                          \n",
    "                    if plot == 'day':\n",
    "                        titles = ['V', 'E1', 'E2', 'Quality Flag']\n",
    "                        Ys = [V, E[:,0], E[:,1]]\n",
    "                        fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(EPOCH, Ys[i])\n",
    "                            axs[i].set_title(titles[i])\n",
    "                            for ind in ind_dust:\n",
    "                                axs[i].axvspan(EPOCH[ind], EPOCH[ind+window_size], alpha=0.5, color='green')\n",
    "                        fig.supxlabel('Time [s]')\n",
    "                        fig.suptitle(date)\n",
    "                        plt.show()\n",
    "                    \n",
    "new_df = pd.DataFrame.from_dict(data_dic, orient='index')\n",
    "new_df = new_df.transpose()\n",
    "#new_df.to_pickle(save_as)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
