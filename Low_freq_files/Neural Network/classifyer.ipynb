{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from data_handling_L1 import get_data, sliding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "PATH_TO_L1 = '//NAS24/solo/remote/data/L1'\n",
    "PATH_TO_MODEL = 'C:/Githubs/kandidat/Low_freq_files/Neural Network/model_low_freq.pt'\n",
    "#Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(E, V, EPOCH, start_ind, window_size=512):\n",
    "    '''Preprocesses data for model.\n",
    "    1. Slices data from start_ind and window_size\n",
    "    2. Shapes into correct format\n",
    "    3. Removes bias\n",
    "    4. Normalizes each input channel with respect to max\n",
    "    Returns pytorch tensor'''\n",
    "    ind = start_ind\n",
    "    #Slice the data for prediction\n",
    "    time_processed = (np.array(EPOCH[ind:ind+window_size]) - EPOCH[ind]) / 10**9 #convert ns to s\n",
    "    E1_window = np.array(E[ind:ind+window_size, 0])\n",
    "    E2_window = np.array(E[ind:ind+window_size, 1])\n",
    "    V_window = np.array(V[ind:ind+window_size])\n",
    "    \n",
    "    #Reshape the data\n",
    "    data_shaped = np.array([V_window, E1_window, E2_window]).reshape(1, 3, 512)\n",
    "    \n",
    "    #Remove bias\n",
    "    median = np.median(data_shaped, axis=2, keepdims=True)\n",
    "    data_nobias = data_shaped - median\n",
    "    \n",
    "    #Normalize data for each channel (3)\n",
    "    max_vals = np.max(np.abs(data_nobias), axis=2, keepdims=True)\n",
    "    data_normalized = data_nobias / max_vals\n",
    "    \n",
    "    #Convert into torch tensor\n",
    "    data_processed = torch.from_numpy(data_normalized).float()\n",
    "    \n",
    "    return time_processed, data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the architecture for the neural net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        #self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(8,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create neural network\n",
    "model = ConvNet()\n",
    "\n",
    "#Load trained variables\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "#Set evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_21376\\2197359738.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-03 00:00:00\n"
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "overlap = 0.2\n",
    "start_date_str = '20220303' #20220302\n",
    "end_date_str = '20220305'\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "\n",
    "plot = 'day'\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "data_dic = {}\n",
    "for root, dirs, files in os.walk(PATH_TO_L1):    #iterate over L1 data\n",
    "    for file in files:\n",
    "        if 'rpw-lfr-surv-cwf-cdag' in file:\n",
    "                date_str = file.split('_')[3]\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                if start_date <= date < end_date:\n",
    "                    CURRENT_PATH = f'{PATH_TO_L1}/{file[-16:-12]}/{file[-12:-10]}/{file[-10:-8]}/{file}'\n",
    "                    #Load file\n",
    "                    E, V, EPOCH  = get_data(CURRENT_PATH)\n",
    "                    #Slice day into windows\n",
    "                    start_indices = sliding_data(E, overlap, window_size)\n",
    "                    ind_dust = []\n",
    "                    predictions = []\n",
    "                    good_pred = []\n",
    "                    recent_pos = False  \n",
    "                    for ind in start_indices:\n",
    "                        #Preprocess data for prediction\n",
    "                        time, data = pre_process(E, V, EPOCH, ind)\n",
    "                        predictions.append(model(data).cpu().detach().numpy()[0][1])\n",
    "                        if predictions[-1] > 0.5 and not recent_pos:\n",
    "                            #recent_pos = True\n",
    "                            ind_dust.append(ind)\n",
    "                            good_pred.append(predictions[-1])\n",
    "                        else:\n",
    "                            recent_pos = False\n",
    "                            \n",
    "                        if plot == 'window' and predictions[-1] > 0.5:\n",
    "                            fig, axs = plt.subplots(3, 1, sharex=True, sharey=True)\n",
    "                            titles = ['V', 'E1', 'E2']\n",
    "                            for i in range(3):\n",
    "                                axs[i].plot(time, data[0, i, :])\n",
    "                                axs[i].set_title(titles[i])\n",
    "                            fig.suptitle(f'Prediction = {predictions[-1]:.2f}')\n",
    "                            fig.supxlabel('Time [s]')\n",
    "                            plt.show()\n",
    "\n",
    "                    print(date)\n",
    "                    data_dic[date_str] = EPOCH[ind_dust]\n",
    "                          \n",
    "                    if plot == 'day':\n",
    "                        fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                        titles = ['V', 'E1', 'E2']\n",
    "                        Ys = [V, E[:,0], E[:,1]]\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(EPOCH, Ys[i], '.')\n",
    "                            axs[i].set_title(titles[i])\n",
    "                            for ind in ind_dust:\n",
    "                                axs[i].axvspan(EPOCH[ind], EPOCH[ind+window_size], alpha=0.5, color='green')\n",
    "                        fig.supxlabel('Time [s]')\n",
    "                        fig.suptitle(date)\n",
    "                        plt.show()\n",
    "                    \n",
    "new_df = pd.DataFrame.from_dict(data_dic, orient='index')\n",
    "new_df = new_df.transpose()\n",
    "new_df.to_pickle('data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
