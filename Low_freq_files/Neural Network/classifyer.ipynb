{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "#import cdflib\n",
    "from datetime import datetime\n",
    "from data_handling_L1 import get_data, sliding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "PATH_TO_L1 = '//NAS24/solo/remote/data/L1'\n",
    "PATH_TO_MODEL = 'C:/Githubs/kandidat/Low_freq_files/Neural Network/model_low_freq.pt'\n",
    "#Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(E, V, EPOCH, start_ind, window_size=512):\n",
    "    '''Preprocesses data for model.\n",
    "    1. Slices data from start_ind and window_size\n",
    "    2. Shapes into correct format\n",
    "    3. Removes bias\n",
    "    4. Normalizes each input channel with respect to max\n",
    "    Returns pytorch tensor'''\n",
    "    ind = start_ind\n",
    "    #Slice the data for prediction\n",
    "    time_processed = (np.array(EPOCH[ind:ind+window_size]) - EPOCH[ind]) / 10**9 #convert ns to s\n",
    "    E1_window = np.array(E[ind:ind+window_size, 0])\n",
    "    E2_window = np.array(E[ind:ind+window_size, 1])\n",
    "    V_window = np.array(V[ind:ind+window_size])\n",
    "    \n",
    "    #Reshape the data\n",
    "    data_shaped = np.array([V_window, E1_window, E2_window]).reshape(3, 512)\n",
    "    \n",
    "    #Remove bias\n",
    "    median = np.median(data_shaped, axis=1, keepdims=True)\n",
    "    data_nobias = data_shaped - median\n",
    "    \n",
    "    #Normalize data for each channel (3)\n",
    "    max_vals = np.max(np.abs(data_nobias), axis=1, keepdims=True)\n",
    "    data_normalized = data_nobias / max_vals\n",
    "    \n",
    "    return time_processed, data_normalized#, problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the architecture for the neural net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(8,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create neural network\n",
    "model = ConvNet()\n",
    "\n",
    "#Load trained variables\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "#Set evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\os.py:368\u001b[0m, in \u001b[0;36m_walk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m     entry \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(scandir_it)\n\u001b[0;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m end_date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mstrptime(end_date_str, \u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m data_dic \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfor\u001b[39;00m root, dirs, files \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mwalk(PATH_TO_L1):    \u001b[39m#iterate over L1 data\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n\u001b[0;32m     19\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrpw-lfr-surv-cwf-cdag\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[39m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[0;32m    415\u001b[0m         \u001b[39m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[0;32m    416\u001b[0m         \u001b[39m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m         \u001b[39m# above.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m         \u001b[39mif\u001b[39;00m followlinks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m islink(new_path):\n\u001b[1;32m--> 419\u001b[0m             \u001b[39myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[0;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[39m# Recurse into sub-directories\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[39mfor\u001b[39;00m new_path \u001b[39min\u001b[39;00m walk_dirs:\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[39m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[0;32m    415\u001b[0m         \u001b[39m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[0;32m    416\u001b[0m         \u001b[39m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m         \u001b[39m# above.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m         \u001b[39mif\u001b[39;00m followlinks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m islink(new_path):\n\u001b[1;32m--> 419\u001b[0m             \u001b[39myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[0;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[39m# Recurse into sub-directories\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[39mfor\u001b[39;00m new_path \u001b[39min\u001b[39;00m walk_dirs:\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\os.py:419\u001b[0m, in \u001b[0;36m_walk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[39m# Issue #23605: os.path.islink() is used instead of caching\u001b[39;00m\n\u001b[0;32m    415\u001b[0m         \u001b[39m# entry.is_symlink() result during the loop on os.scandir() because\u001b[39;00m\n\u001b[0;32m    416\u001b[0m         \u001b[39m# the caller can replace the directory entry during the \"yield\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m         \u001b[39m# above.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m         \u001b[39mif\u001b[39;00m followlinks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m islink(new_path):\n\u001b[1;32m--> 419\u001b[0m             \u001b[39myield from\u001b[39;00m _walk(new_path, topdown, onerror, followlinks)\n\u001b[0;32m    420\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[39m# Recurse into sub-directories\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[39mfor\u001b[39;00m new_path \u001b[39min\u001b[39;00m walk_dirs:\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\os.py:368\u001b[0m, in \u001b[0;36m_walk\u001b[1;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    367\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 368\u001b[0m         entry \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(scandir_it)\n\u001b[0;32m    369\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "overlap = 0.2\n",
    "batch_size = 100\n",
    "\n",
    "save_as = 'data.pkl'\n",
    "plot = 'window'\n",
    "%matplotlib inline\n",
    "#%matplotlib qt\n",
    "\n",
    "start_date_str = '20230311' #20220302\n",
    "end_date_str = '20230312'\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "\n",
    "data_dic = {}\n",
    "for root, dirs, files in os.walk(PATH_TO_L1):    #iterate over L1 data\n",
    "    for file in files:\n",
    "        if 'rpw-lfr-surv-cwf-cdag' in file:\n",
    "                date_str = file.split('_')[3]\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                if start_date <= date < end_date:\n",
    "                    CURRENT_PATH = f'{PATH_TO_L1}/{file[-16:-12]}/{file[-12:-10]}/{file[-10:-8]}/{file}'\n",
    "                    #Load file\n",
    "                    E, V, EPOCH  = get_data(CURRENT_PATH)\n",
    "                    Ys = [V, E[:,0], E[:,1]]\n",
    "                    #Slice day into windows\n",
    "                    start_indices = sliding_data(E, overlap, window_size)\n",
    "                    good_ind = []\n",
    "                    ind_dust = []\n",
    "                    predictions = np.array([])\n",
    "                    good_pred = []\n",
    "                    for i in range(0, len(start_indices), batch_size):\n",
    "                        batch_indices = start_indices[i:i+batch_size]\n",
    "                        batch_time = []\n",
    "                        batch_data = []\n",
    "                        for ind in batch_indices:\n",
    "                            #Preprocess data for prediction\n",
    "                            time, data = pre_process(E, V, EPOCH, ind)\n",
    "                            for i in range(len(time) - 1):\n",
    "                                #Lowest time between data points should be 1/16 s\n",
    "                                if time[i+1] - time[i] > 0.063:\n",
    "                                    print('Gap in data detected')\n",
    "                                    break\n",
    "                            else:\n",
    "                                batch_time.append(time)\n",
    "                                batch_data.append(data)\n",
    "                                good_ind.append(ind)\n",
    "                                \n",
    "                        model_data = torch.from_numpy(np.stack(batch_data, 0)).to(device)       \n",
    "                        batch_pred = model(model_data).cpu().detach().numpy()[:,1]\n",
    "                        predictions = np.append(predictions, batch_pred)\n",
    "\n",
    "                    print(len(good_ind))\n",
    "                    prev_pos = False\n",
    "                    if plot == 'window':\n",
    "                        titles = ['V', 'E1', 'E2', 'Quality Flag']\n",
    "                        #Qflag = cdflib.cdfread.CDF(CURRENT_PATH)['BIAS_ON_OFF']\n",
    "                        Ys = [V, E[:,0], E[:,1]]    \n",
    "                    for i in range(len(predictions)):\n",
    "                        if predictions[i] > 0.5 and not prev_pos:\n",
    "                            prev_pos = True\n",
    "                            ind_dust.append(good_ind[i])\n",
    "                            if plot == 'window':\n",
    "                                fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                                for i_plt in range(3):\n",
    "                                    axs[i_plt].plot(EPOCH[ind_dust[-1]:ind_dust[-1]+window_size], \\\n",
    "                                        Ys[i_plt][ind_dust[-1]:ind_dust[-1]+window_size])\n",
    "                                    axs[i_plt].set_title(titles[i_plt])\n",
    "                                #axs[3].plot(EPOCH[ind_dust[-1]:ind_dust[-1]+window_size], Qflag[ind_dust[-1]:ind_dust[-1]+window_size])\n",
    "                                fig.suptitle(f'Prediction = {predictions[i]:.2f}')\n",
    "                                fig.supxlabel('Time [ns]')\n",
    "                                plt.show()\n",
    "                        else:\n",
    "                            prev_pos = False                        \n",
    "\n",
    "                    print(date)\n",
    "                    data_dic[date_str] = (EPOCH[ind_dust], predictions[ind_dust])\n",
    "                          \n",
    "                    if plot == 'day':\n",
    "                        titles = ['V', 'E1', 'E2', 'Quality Flag']\n",
    "                        Ys = [V, E[:,0], E[:,1]]\n",
    "                        fig, axs = plt.subplots(len(Ys), 1, sharex=True)\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(EPOCH, Ys[i])\n",
    "                            axs[i].set_title(titles[i])\n",
    "                            for ind in ind_dust:\n",
    "                                axs[i].axvspan(EPOCH[ind], EPOCH[ind+window_size], alpha=0.5, color='green')\n",
    "                        fig.supxlabel('Time [s]')\n",
    "                        fig.suptitle(date)\n",
    "                        plt.show()\n",
    "                    \n",
    "new_df = pd.DataFrame.from_dict(data_dic, orient='index')\n",
    "new_df = new_df.transpose()\n",
    "new_df.to_pickle(save_as)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
