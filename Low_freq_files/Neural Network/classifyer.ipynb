{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from data_handling_L1 import get_data, sliding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "PATH_TO_L1 = '//NAS24/solo/remote/data/L1'\n",
    "PATH_TO_MODEL = 'C:/Githubs/kandidat/Low_freq_files/Neural Network/model_low_freq.pt'\n",
    "#Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(E, V, EPOCH, start_ind, window_size=512):\n",
    "    '''Preprocesses data for model.\n",
    "    1. Slices data from start_ind and window_size\n",
    "    2. Shapes into correct format\n",
    "    3. Removes bias\n",
    "    4. Normalizes each input channel with respect to max\n",
    "    Returns pytorch tensor'''\n",
    "    ind = start_ind\n",
    "    #Slice the data for prediction\n",
    "    time_processed = (np.array(EPOCH[ind:ind+window_size]) - EPOCH[ind]) / 10**9 #convert ns to s\n",
    "    E1_window = np.array(E[ind:ind+window_size, 0])\n",
    "    E2_window = np.array(E[ind:ind+window_size, 1])\n",
    "    V_window = np.array(V[ind:ind+window_size])\n",
    "    \n",
    "    #Reshape the data\n",
    "    data_shaped = np.array([V_window, E1_window, E2_window]).reshape(1, 3, 512)\n",
    "    \n",
    "    #Remove bias\n",
    "    median = np.median(data_shaped, axis=2, keepdims=True)\n",
    "    data_nobias = data_shaped - median\n",
    "    \n",
    "    #Normalize data for each channel (3)\n",
    "    max_vals = np.max(data_nobias, axis=2, keepdims=True)\n",
    "    data_normalized = data_nobias / max_vals\n",
    "    \n",
    "    #Convert into torch tensor\n",
    "    data_processed = torch.from_numpy(data_normalized).float()\n",
    "    return time_processed, data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the architecture for the neural net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(8,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create neural network\n",
    "model = ConvNet()\n",
    "\n",
    "#Load trained variables\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=device))\n",
    "\n",
    "#Set evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_24140\\4219561328.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_24140\\3097215369.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  data_normalized = data_nobias / max_vals\n",
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_24140\\3097215369.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  data_normalized = data_nobias / max_vals\n",
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_24140\\3346989729.py:33: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(3, 1, sharex=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m start_indices:\n\u001b[0;32m     26\u001b[0m     \u001b[39m#Preprocess data for prediction\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     time, data \u001b[39m=\u001b[39m pre_process(E, V, EPOCH, ind)\n\u001b[1;32m---> 28\u001b[0m     predictions\u001b[39m.\u001b[39mappend(model(data)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])\n\u001b[0;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m predictions[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0.9\u001b[39m:\n\u001b[0;32m     30\u001b[0m         ind_dust\u001b[39m.\u001b[39mappend(ind)\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[0;32m     27\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x)\n\u001b[1;32m---> 29\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)\n\u001b[0;32m     30\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(x)\n\u001b[0;32m     31\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu2(x)\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "start_date_str = '20230301'\n",
    "end_date_str = '20230302'\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "\n",
    "plot = 'window'\n",
    "%matplotlib qt\n",
    "\n",
    "data_dic = {}\n",
    "for root, dirs, files in os.walk(PATH_TO_L1):    #iterate over L1 data\n",
    "    for file in files:\n",
    "        if 'rpw-lfr-surv-cwf-cdag' in file:\n",
    "                date_str = file.split('_')[3]\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                if start_date <= date < end_date:\n",
    "                    CURRENT_PATH = f'{PATH_TO_L1}/{file[-16:-12]}/{file[-12:-10]}/{file[-10:-8]}/{file}'\n",
    "                    #Load file\n",
    "                    E, V, EPOCH  = get_data(CURRENT_PATH)\n",
    "                    #Slice day into windows\n",
    "                    start_indices = sliding_data(E)\n",
    "                    ind_dust = []\n",
    "                    predictions = []         \n",
    "                    for ind in start_indices:\n",
    "                        #Preprocess data for prediction\n",
    "                        time, data = pre_process(E, V, EPOCH, ind)\n",
    "                        predictions.append(model(data).cpu().detach().numpy()[0][1])\n",
    "                        if predictions[-1] > 0.9:\n",
    "                            ind_dust.append(ind)\n",
    "                            \n",
    "                        if plot == 'window' and predictions[-1] > 0.5:\n",
    "                            fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                            titles = ['V', 'E1', 'E2']\n",
    "                            for i in range(3):\n",
    "                                axs[i].plot(time, data[0, i, :])\n",
    "                                axs[i].set_title(titles[i])\n",
    "                            fig.suptitle(f'Prediction = {predictions[-1]:.2f}')\n",
    "                            fig.supxlabel('Time [s]')\n",
    "                            plt.show()\n",
    "                    print(date)\n",
    "                    data_dic[date_str] = EPOCH[ind_dust]      \n",
    "                    if plot == 'day':\n",
    "                        fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                        titles = ['V', 'E1', 'E2']\n",
    "                        Ys = [V, E[:,0], E[:,1]]\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(EPOCH, Ys[i])\n",
    "                            axs[i].set_title(titles[i])\n",
    "                            for ind in ind_dust:\n",
    "                                axs[i].axvspan(EPOCH[ind], EPOCH[ind+window_size], alpha=0.5, color='green')\n",
    "                        fig.supxlabel('Time [ns]')\n",
    "                        fig.suptitle(date)\n",
    "                        plt.show()\n",
    "                    \n",
    "new_df = pd.DataFrame.from_dict(data_dic, orient='index')\n",
    "new_df = new_df.transpose()\n",
    "new_df.to_pickle('data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
