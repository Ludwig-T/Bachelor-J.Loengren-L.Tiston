{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from data_handling_L1 import get_data, sliding_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "PATH_TO_L1 = '//NAS24/solo/remote/data/L1'\n",
    "PATH_TO_MODEL = 'C:/Githubs/kandidat/Low_freq_files/Neural Network/model_low_freq.pt'\n",
    "#Use GPU if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(E, V, EPOCH, start_ind, window_size=512):\n",
    "    '''Preprocesses data for model.\n",
    "    1. Slices data from start_ind and window_size\n",
    "    2. Shapes into correct format\n",
    "    3. Removes bias\n",
    "    4. Normalizes each input channel with respect to max\n",
    "    Returns pytorch tensor'''\n",
    "    ind = start_ind\n",
    "    #Slice the data for prediction\n",
    "    time_processed = (np.array(EPOCH[ind:ind+window_size]) - EPOCH[ind]) / 10**9 #convert ns to s\n",
    "    E1_window = np.array(E[ind:ind+window_size, 0])\n",
    "    E2_window = np.array(E[ind:ind+window_size, 1])\n",
    "    V_window = np.array(V[ind:ind+window_size])\n",
    "    \n",
    "    #Reshape the data\n",
    "    data_shaped = np.array([V_window, E1_window, E2_window]).reshape(3, 512)\n",
    "    \n",
    "    #Remove bias\n",
    "    median = np.median(data_shaped, axis=1, keepdims=True)\n",
    "    data_nobias = data_shaped - median\n",
    "    \n",
    "    #Normalize data for each channel (3)\n",
    "    max_vals = np.max(np.abs(data_nobias), axis=1, keepdims=True)\n",
    "    data_normalized = data_nobias / max_vals\n",
    "    \n",
    "    maxes = np.max(data_nobias, axis=1, keepdims=True)\n",
    "    minis = np.min(data_nobias, axis=1, keepdims=True)\n",
    "    '''\n",
    "    for mn, mx in minis, maxes:\n",
    "        if mx-mn > 10000:\n",
    "            '''\n",
    "    return time_processed, data_normalized#, problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the architecture for the neural net\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        #self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        #x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 128, kernel_size=(8,), stride=(1,))\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create neural network\n",
    "model = ConvNet()\n",
    "\n",
    "#Load trained variables\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL, map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "#Set evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ludwi\\AppData\\Local\\Temp\\ipykernel_23320\\2197359738.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "Gap in data detected\n",
      "3399\n",
      "3499\n",
      "3599\n",
      "3699\n",
      "3799\n",
      "3899\n",
      "3999\n",
      "4099\n",
      "4199\n",
      "4299\n",
      "4399\n",
      "4499\n",
      "4599\n",
      "4699\n",
      "4799\n",
      "Gap in data detected\n",
      "Gap in data detected\n",
      "4897\n",
      "4997\n",
      "Gap in data detected\n",
      "5096\n",
      "5196\n",
      "5296\n",
      "5396\n",
      "5496\n",
      "5596\n",
      "5696\n",
      "5796\n",
      "5896\n",
      "5996\n",
      "6096\n",
      "6196\n",
      "6296\n",
      "6396\n",
      "6496\n",
      "6596\n",
      "6696\n",
      "6796\n",
      "6896\n",
      "6996\n",
      "7096\n",
      "7196\n",
      "7296\n",
      "7396\n",
      "7496\n",
      "7596\n",
      "7696\n",
      "7796\n",
      "7896\n",
      "7996\n",
      "8096\n",
      "8196\n",
      "8296\n",
      "8396\n",
      "8496\n",
      "8596\n",
      "8696\n",
      "8796\n",
      "8896\n",
      "8996\n",
      "9096\n",
      "9196\n",
      "9296\n",
      "9396\n",
      "9496\n",
      "9596\n",
      "9696\n",
      "9796\n",
      "9896\n",
      "9996\n",
      "10096\n",
      "10196\n",
      "10296\n",
      "10396\n",
      "10496\n",
      "10596\n",
      "10696\n",
      "10796\n",
      "10896\n",
      "10996\n",
      "11096\n",
      "11196\n",
      "11296\n",
      "11396\n",
      "11496\n",
      "11596\n",
      "11696\n",
      "11796\n",
      "11896\n",
      "11996\n",
      "12096\n",
      "12196\n",
      "12296\n",
      "12396\n",
      "12496\n",
      "12596\n",
      "12696\n",
      "12796\n",
      "12896\n",
      "12996\n",
      "13096\n",
      "13196\n",
      "13296\n",
      "13396\n",
      "13496\n",
      "13596\n",
      "13696\n",
      "13796\n",
      "13896\n",
      "13996\n",
      "14096\n",
      "14196\n",
      "14296\n",
      "14396\n",
      "14496\n",
      "14596\n",
      "14696\n",
      "14796\n",
      "14896\n",
      "14996\n",
      "15096\n",
      "15196\n",
      "15296\n",
      "15396\n",
      "15496\n",
      "15596\n",
      "15696\n",
      "15796\n",
      "15896\n",
      "15996\n",
      "16096\n",
      "16196\n",
      "16296\n",
      "16396\n",
      "16496\n",
      "16596\n",
      "16696\n",
      "16796\n",
      "16896\n",
      "16996\n",
      "17096\n",
      "17196\n",
      "17296\n",
      "17396\n",
      "17496\n",
      "17596\n",
      "17696\n",
      "17796\n",
      "17896\n",
      "17996\n",
      "18096\n",
      "18196\n",
      "18296\n",
      "18396\n",
      "18496\n",
      "18596\n",
      "18696\n",
      "18796\n",
      "18896\n",
      "18996\n",
      "19096\n",
      "19196\n",
      "19296\n",
      "19396\n",
      "19496\n",
      "19596\n",
      "19696\n",
      "19796\n",
      "19896\n",
      "19996\n",
      "20096\n",
      "20196\n",
      "20296\n",
      "20396\n",
      "20496\n",
      "20596\n",
      "20696\n",
      "20796\n",
      "20896\n",
      "20996\n",
      "21096\n",
      "21196\n",
      "21296\n",
      "21396\n",
      "21496\n",
      "21596\n",
      "21696\n",
      "21796\n",
      "21896\n",
      "21996\n",
      "22096\n",
      "22196\n",
      "22296\n",
      "22396\n",
      "22496\n",
      "22596\n",
      "22696\n",
      "22796\n",
      "22896\n",
      "22996\n",
      "23096\n",
      "23196\n",
      "23296\n",
      "23396\n",
      "23496\n",
      "23596\n",
      "23696\n",
      "23796\n",
      "23896\n",
      "23996\n",
      "24096\n",
      "24196\n",
      "24296\n",
      "24396\n",
      "24496\n",
      "24596\n",
      "24696\n",
      "24796\n",
      "24896\n",
      "24996\n",
      "25096\n",
      "25196\n",
      "25296\n",
      "25396\n",
      "25496\n",
      "25596\n",
      "25696\n",
      "25796\n",
      "25896\n",
      "25996\n",
      "26096\n",
      "26196\n",
      "26296\n",
      "26396\n",
      "26496\n",
      "26596\n",
      "26696\n",
      "26796\n",
      "26896\n",
      "26996\n",
      "27096\n",
      "27196\n",
      "27296\n",
      "27396\n",
      "27496\n",
      "27596\n",
      "27696\n",
      "27796\n",
      "27896\n",
      "27996\n",
      "28096\n",
      "28196\n",
      "28296\n",
      "28396\n",
      "28496\n",
      "28596\n",
      "28696\n",
      "28775\n",
      "28775\n",
      "28775\n",
      "2022-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "window_size = 512\n",
    "overlap = 0.2\n",
    "batch_size = 100\n",
    "start_date_str = '20220101' #20220302\n",
    "end_date_str = '20220102'\n",
    "\n",
    "start_date = datetime.strptime(start_date_str, '%Y%m%d')\n",
    "end_date = datetime.strptime(end_date_str, '%Y%m%d')\n",
    "\n",
    "plot = 'day'\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "data_dic = {}\n",
    "for root, dirs, files in os.walk(PATH_TO_L1):    #iterate over L1 data\n",
    "    for file in files:\n",
    "        if 'rpw-lfr-surv-cwf-cdag' in file:\n",
    "                date_str = file.split('_')[3]\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                if start_date <= date < end_date:\n",
    "                    CURRENT_PATH = f'{PATH_TO_L1}/{file[-16:-12]}/{file[-12:-10]}/{file[-10:-8]}/{file}'\n",
    "                    #Load file\n",
    "                    E, V, EPOCH  = get_data(CURRENT_PATH)\n",
    "                    #Slice day into windows\n",
    "                    start_indices = sliding_data(E, overlap, window_size)\n",
    "                    good_ind = []\n",
    "                    ind_dust = []\n",
    "                    predictions = np.array([])\n",
    "                    good_pred = []\n",
    "                    recent_pos = False\n",
    "                    for i in range(0, len(start_indices), batch_size):\n",
    "                        batch_indices = start_indices[i:i+batch_size]\n",
    "                        batch_time = []\n",
    "                        batch_data = []\n",
    "                        for ind in batch_indices:\n",
    "                            #Preprocess data for prediction\n",
    "                            time, data = pre_process(E, V, EPOCH, ind)\n",
    "                            if time[-1] - time[0] < 32: \n",
    "                                batch_time.append(time)\n",
    "                                batch_data.append(data)\n",
    "                                good_ind.append(ind)\n",
    "                            else:\n",
    "                                print('Gap in data detected')\n",
    "                        model_data = torch.from_numpy(np.stack(batch_data, 0)).to(device)       \n",
    "                        batch_pred = model(model_data).cpu().detach().numpy()[:,1]\n",
    "                        predictions = np.append(predictions, batch_pred)\n",
    "                        print(len(predictions))\n",
    "                    print(len(predictions))\n",
    "                    print(len(good_ind))    \n",
    "                    for i in range(len(predictions)):\n",
    "                        if predictions[i] > 0.5:\n",
    "                            ind_dust.append(good_ind[i]) \n",
    "                            \n",
    "                    '''if plot == 'window' and predictions[-1] > 0.5:\n",
    "                        fig, axs = plt.subplots(3, 1, sharex=True, sharey=True)\n",
    "                        titles = ['V', 'E1', 'E2']\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(time, data[0, i, :])\n",
    "                            axs[i].set_title(titles[i])\n",
    "                        fig.suptitle(f'Prediction = {predictions[-1]:.2f}')\n",
    "                        fig.supxlabel('Time [s]')\n",
    "                        plt.show()'''\n",
    "\n",
    "                    print(date)\n",
    "                    data_dic[date_str] = EPOCH[ind_dust]\n",
    "                          \n",
    "                    if plot == 'day':\n",
    "                        fig, axs = plt.subplots(3, 1, sharex=True)\n",
    "                        titles = ['V', 'E1', 'E2']\n",
    "                        Ys = [V, E[:,0], E[:,1]]\n",
    "                        for i in range(3):\n",
    "                            axs[i].plot(EPOCH, Ys[i])\n",
    "                            axs[i].set_title(titles[i])\n",
    "                            for ind in ind_dust:\n",
    "                                axs[i].axvspan(EPOCH[ind], EPOCH[ind+window_size], alpha=0.5, color='green')\n",
    "                        fig.supxlabel('Time [s]')\n",
    "                        fig.suptitle(date)\n",
    "                        plt.show()\n",
    "                    \n",
    "new_df = pd.DataFrame.from_dict(data_dic, orient='index')\n",
    "new_df = new_df.transpose()\n",
    "new_df.to_pickle('data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
