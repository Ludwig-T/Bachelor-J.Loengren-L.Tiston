{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for training neural network on LF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from data_handling_L1 import pre_process\n",
    "\n",
    "np.random.seed(42)\n",
    "### Import data from pickle\n",
    "data_path = 'C:/Users/joarl/OneDrive/Dokument/Skola/Kand/Kod_git/kandidat/Low_freq_files/data_files_2s.pkl'\n",
    "\n",
    "save_model_name = 'model_low_freq.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/joarl/OneDrive/Dokument/Skola/Kand/Kod_git/kandidat/Low_freq_files/data_files_2s.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# use GPU for computations if possible\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(data_path, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     data_list \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      8\u001b[0m \u001b[39m### prerocess ---------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ludwi\\anaconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/joarl/OneDrive/Dokument/Skola/Kand/Kod_git/kandidat/Low_freq_files/data_files_2s.pkl'"
     ]
    }
   ],
   "source": [
    "# use GPU for computations if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "    \n",
    "### prerocess ---------------------\n",
    "\n",
    "data_processed = pre_process(data_list) \n",
    "\n",
    "labels = [t[1] for t in data_processed]\n",
    "data = [t[2] for t in data_processed]\n",
    "\n",
    "### split data (80/20) ------------------------------  \n",
    "\n",
    "train_data = data[:11500]\n",
    "train_labels = labels[:11500]\n",
    "\n",
    "test_data = data[-3000:]\n",
    "test_labels = labels[-3000:]\n",
    "\n",
    "# create NumPy arrays from the data and labels\n",
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "### convert into tensors ------------------------\n",
    "\n",
    "train_data_reshaped = train_data.reshape(11500, 3, 512)\n",
    "test_data_reshaped = test_data.reshape(3000, 3, 512)\n",
    "\n",
    "train_labels_tensor = torch.from_numpy(train_labels).float()\n",
    "train_data_tensor = torch.from_numpy(train_data_reshaped).float()\n",
    "test_labels_tensor = torch.from_numpy(test_labels).float()\n",
    "test_data_tensor = torch.from_numpy(test_data_reshaped).float()\n",
    "\n",
    "#create teststet -----------------------------------------\n",
    "trainset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
    "testset = TensorDataset(test_data_tensor, test_labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define all parameters\n",
    "total_iterations = 2000 # total number of iterations\n",
    "batch_size = 100\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=128, kernel_size=8, stride=1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=5, stride=1)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(128, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(G, Y):\n",
    "    # convert labels to onehot encoding\n",
    "    Y_onehot = torch.eye(10)[Y]\n",
    "\n",
    "    return -(Y_onehot * G.log()).sum(dim = 1).mean()\n",
    "\n",
    "def accuracy(G, Y):\n",
    "    return (G.argmax(dim=1) == Y).float().mean()\n",
    "\n",
    "\n",
    "# initialize the test and training error statistics\n",
    "test_accuracy = []\n",
    "test_crossentropy = []\n",
    "test_iter = []\n",
    "train_accuracy = []\n",
    "train_crossentropy = []\n",
    "train_iter = []\n",
    "\n",
    "# initialize the neural network and move it to the GPU if needed\n",
    "net = ConvNet()\n",
    "net.to(device)\n",
    "\n",
    "# define the optimization algorithm\n",
    "learningrate = 0.001  \n",
    "optimizer = optim.Adam(net.parameters(), lr=learningrate)\n",
    "\n",
    "# define the data loader for batches of the training data\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=1000, shuffle=True)\n",
    "\n",
    "t = 0 # current iteration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joarl\\AppData\\Local\\Temp\\ipykernel_3688\\2512127549.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x, dtype=self.conv1.weight.dtype).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: train accuracy  80.00% train cross-entropy  0.67  test accuracy  97.60% test cross-entropy  0.46\n",
      "Step     0: train accuracy  80.00% train cross-entropy  0.67  test accuracy  98.20% test cross-entropy  0.46\n",
      "Step     0: train accuracy  80.00% train cross-entropy  0.67  test accuracy  97.20% test cross-entropy  0.46\n",
      "Step   100: train accuracy  97.00% train cross-entropy  0.34  test accuracy  99.60% test cross-entropy  0.32\n",
      "Step   100: train accuracy  97.00% train cross-entropy  0.34  test accuracy  98.70% test cross-entropy  0.33\n",
      "Step   100: train accuracy  97.00% train cross-entropy  0.34  test accuracy  98.60% test cross-entropy  0.33\n",
      "Step   200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step   200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  98.80% test cross-entropy  0.33\n",
      "Step   200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step   300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step   300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  98.90% test cross-entropy  0.33\n",
      "Step   300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  98.70% test cross-entropy  0.33\n",
      "Step   400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step   400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  98.50% test cross-entropy  0.33\n",
      "Step   400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step   500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  98.30% test cross-entropy  0.33\n",
      "Step   500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step   500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.70% test cross-entropy  0.32\n",
      "Step   600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step   600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step   600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step   700: train accuracy  98.00% train cross-entropy  0.34  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step   700: train accuracy  98.00% train cross-entropy  0.34  test accuracy  99.70% test cross-entropy  0.32\n",
      "Step   700: train accuracy  98.00% train cross-entropy  0.34  test accuracy  98.80% test cross-entropy  0.33\n",
      "Step   800: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step   800: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step   800: train accuracy  98.00% train cross-entropy  0.33  test accuracy  98.80% test cross-entropy  0.33\n",
      "Step   900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step   900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.40% test cross-entropy  0.32\n",
      "Step   900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1000: train accuracy 100.00% train cross-entropy  0.31  test accuracy  98.90% test cross-entropy  0.32\n",
      "Step  1000: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1000: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step  1100: train accuracy  99.00% train cross-entropy  0.33  test accuracy  98.90% test cross-entropy  0.32\n",
      "Step  1100: train accuracy  99.00% train cross-entropy  0.33  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step  1100: train accuracy  99.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step  1200: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step  1300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step  1300: train accuracy  99.00% train cross-entropy  0.33  test accuracy  98.70% test cross-entropy  0.32\n",
      "Step  1400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step  1400: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step  1500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step  1500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1500: train accuracy  98.00% train cross-entropy  0.33  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  98.90% test cross-entropy  0.32\n",
      "Step  1600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1600: train accuracy 100.00% train cross-entropy  0.31  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1700: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step  1700: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1700: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.00% test cross-entropy  0.32\n",
      "Step  1800: train accuracy 100.00% train cross-entropy  0.32  test accuracy  99.10% test cross-entropy  0.32\n",
      "Step  1800: train accuracy 100.00% train cross-entropy  0.32  test accuracy  99.50% test cross-entropy  0.32\n",
      "Step  1800: train accuracy 100.00% train cross-entropy  0.32  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step  1900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.40% test cross-entropy  0.32\n",
      "Step  1900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  1900: train accuracy  99.00% train cross-entropy  0.32  test accuracy  98.80% test cross-entropy  0.32\n",
      "Step  2000: train accuracy  96.00% train cross-entropy  0.35  test accuracy  99.30% test cross-entropy  0.32\n",
      "Step  2000: train accuracy  96.00% train cross-entropy  0.35  test accuracy  99.20% test cross-entropy  0.32\n",
      "Step  2000: train accuracy  96.00% train cross-entropy  0.35  test accuracy  99.20% test cross-entropy  0.32\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    for (batch_X, batch_Y) in trainloader:\n",
    "        # move batch to the GPU if needed\n",
    "        batch_Y = batch_Y.type(torch.LongTensor)\n",
    "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        batch_G = net(batch_X)\n",
    "        loss = F.cross_entropy(batch_G, batch_Y)\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        # perform gradient descent step\n",
    "        optimizer.step()\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            # evaluate the performance on the training data at every 5th iteration\n",
    "            if t % 5 == 0:\n",
    "                train_crossentropy.append(loss.item())\n",
    "                train_accuracy.append(accuracy(batch_G, batch_Y).item())\n",
    "                train_iter.append(t) \n",
    "                \n",
    "            # evaluate the performance on the test data at every 100th iteration\n",
    "            if t % 100 == 0:\n",
    "                for (test_X, test_Y) in testloader:\n",
    "                    # move batch to the GPU if needed\n",
    "                    test_Y = test_Y.type(torch.LongTensor)\n",
    "                    X, Y = test_X.to(device), test_Y.to(device)\n",
    "\n",
    "                    # compute predictions for the test data\n",
    "                    G = net(X)\n",
    "                    test_crossentropy.append(F.cross_entropy(G, Y).item())\n",
    "                    test_accuracy.append(accuracy(G, Y).item())\n",
    "                    test_iter.append(t)\n",
    "\n",
    "                    # print the iteration number and the accuracy of the predictions\n",
    "                    print(f\"Step {t:5d}: train accuracy {100 * train_accuracy[-1]:6.2f}% \" \\\n",
    "                        f\"train cross-entropy {train_crossentropy[-1]:5.2f}  \" \\\n",
    "                        f\"test accuracy {100 * test_accuracy[-1]:6.2f}% \" \\\n",
    "                        f\"test cross-entropy {test_crossentropy[-1]:5.2f}\")\n",
    "            \n",
    "        # stop the training after the specified number of iterations\n",
    "        t += 1\n",
    "        if t > total_iterations:\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "torch.save(net.state_dict(), save_model_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
